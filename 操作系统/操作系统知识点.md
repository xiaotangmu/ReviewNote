原文链接：https://blog.csdn.net/Sugar_Z_/article/details/51526696

操作系统的基本特征

    并发：同一段时间内多个程序执行(注意区别并发和并行，前者是同一时刻的多个事件，后者是统一时间段内的多个事件)
    共享：系统中的资源可以被内存中多个并发执行的进线程共同使用
    虚拟：通过时分复用（如分时系统）以及空分复用（如虚拟内存）技术实现把一个物理实体虚拟为多个
    异步：系统中的进程是以走走停停的方式执行的，且以一种不可预知的速度推进

操作系统的主要功能

    处理机管理：处理机分配都是以进程为单位，所以处理机管理也被看做是进程管理。包括进程控制，进程同步，进程通信和进程调度
    存储器管理（或者内存管理）：内存分配，内存保护，地址映射，内存扩充
    设备管理：管理所有外围设备，包括完成用户的IO请求；为用户进程分配IO设备；提高IO设备利用率；提高IO速度；方便IO的使用
    文件管理：管理用户文件和系统文件，方便使用同时保证安全性。包括：磁盘存储空间管理，目录管理，文件读写管理以及文件共享和保护
    提供用户接口：程序接口（如API）和用户接口（如GUI）

进程和线程的区别

进程：进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位（具有动态、并发、独立、异步的特性，以及就绪、执行、阻塞3种状态；也有5状态或者7状态；资源拥有单位的属性）；引入进程是为了使多个程序可以并发的执行，以提高系统的资源利用率和吞吐量。

线程：是比进程更小的可独立运行的基本单位，可以看做是轻量级的进程（具有轻型实体，独立调度分派单位，可并发执行，共享进程资源等属性）；引入目的是为了减少程序在并发执行过程中的开销，使OS的并发效率更高。

两者的对比：
1. 调度方面：在引入线程的OS中，线程是独立的调度和分派单位，而进程作为资源的拥有单位(相当于把未引入线程的传统OS中的进程的两个属性分开了)。由于线程不拥有资源，因此可以显著的提高并发度以及减少切换开销。
2. 并发性：引入了线程的OS中，进程间可以并发，而且一个进程内部的多个线程之间也是可以并发的，这就使OS具有更好的并发性，有效的提高了系统资源利用率和吞吐量。
3. 拥有资源：无论OS是否支持线程，进程都是基本的资源拥有单位，线程只拥有很少的基本的资源，但是线程可以访问所隶属的进程的资源（进程的代码段，数据段和所拥有的系统资源如fd）
4. 系统开销：创建或者撤销进程的时候，系统要为之创建或回收PCB，系统资源等，切换时也需要保存和恢复CPU环境。而线程的切换只需要保存和恢复少量的寄存器，不涉及存储器管理方面的工作，所以开销较小。此外，统一进程中的多个线程由于共享地址空间，所以通信同步等都比较方便。
  进程的几种状态

主要是3中基本状态，5状态和7状态可以直接看书
1. 就绪状态：进程获得了除了CPU之外的所有的必要资源，只要获得CPU就可以立即执行，此时的进程处于就绪态
2. 执行状态：进程已经获得CPU，正在运行，在多处理其系统中，会有多个进程同时处于运行状态
3. 阻塞状态：处于执行状态的进程由于发生某些事件而暂时无法继续执行，放弃处理机而处于暂停状态，此时进程就处于阻塞（执行受到阻塞）状态

就绪->执行：调度进程为其分配了处理机
执行->就绪：时间片用完
执行->阻塞：申请临界资源而未被满足，如IO请求或者申请缓存
阻塞->就绪：请求得到满足，如IO完成
进程同步

多进程虽然提高了系统资源利用率和吞吐量，但是由于进程的异步性可能造成系统的混乱。进程同步的任务就是对多个相关进程在执行顺序上进行协调，使并发执行的多个进程之间可以有效的共享资源和相互合作，保证程序执行的可再现性

同步机制需要遵循的原则：
1. 空闲让进：当没有进程处于临界区的时候，应该许可其他进程进入临界区的申请
2. 忙则等待：当前如果有进程处于临界区，如果有其他进程申请进入，则必须等待，保证对临界区的互斥访问
3. 有限等待：对要求访问临界资源的进程，需要在有限时间呃逆进入临界区，防止出现死等
4. 让权等待：当进程无法进入临界区的时候，需要释放处理机，边陷入忙等

经典的进程同步问题：生产者-消费者问题；哲学家进餐问题；读者-写者问题
进程间通信

进程通信就是指进程间的信息交换，交换信息可以使一个状态，也可以是很多的byte。进程间同步互斥也存在信息的交换，因此也属于是一种IPC，属于是低级通信。该低级通信存在的问题：1）通信的数据量太少；2）通信对用户不透明(数据的传递或者同步互斥都需要程序员实现)

高级通信机制（高级通信的通信细节被OS隐藏，因此使用起来增加方便而且可以传送大量的数据，尤其是管道通信）：
1. 共享存储器系统：相互通信的进程共享某些数据结构或者是存储区，进程之间可以通过这些共享空间进行通信。分为：1）基于共享数据结构的通信，如生产者消费者系统中的有界缓冲区；2）基于共享存储区的通信，可以传输大量数据，通信的进程之间可以像读写普通存储器一样读写共享存储区
2. 消息传递系统：进程间通信采用的是格式化的消息，可以直接使用OS提供的消息发送或者接受原语进行通信。由于隐藏了通信细节，所以简化了通信程序的复杂性
3. 管道通信：管道是连接两个一个读进程和一个写进程之间用于实现数据交换的一个共享文件。为了协调管道通信双方，需要管道机制实现如下功能：1）互斥：统一时刻只能有一个进程对管道进行读写；2）同步：当读端发现管道为空的时候需要睡眠等待，直到有数据时候被唤醒，相应的写端也是在管道已满的时候等待直到被唤醒；3）确定对方的存在性：只有同时有读端和写端，管道才有存在意义
  进程/任务调度算法

基本调度算法：
1. 先来先服务调度算法FCFS：既可以作为作业调度算法也可以作为进程调度算法；按作业或者进程到达的先后顺序依次调度；因此对于长作业比较有利；
2. 短作业优先调度算法SJ(P)F：作业调度算法，算法从就绪队列中选择估计时间最短的作业进行处理，直到得出结果或者无法继续执行；缺点：不利于长作业；未考虑作业的重要性；运行时间是预估的，并不靠谱
3. 高优先权优先调度算法HPF：既可以作为作业调度也可以作为进程调度算法；调度作业时，从就绪队列中选择优先级最高的作业进行处理；由于涉及到了优先级，因此可以分为抢占式和非抢占式；而且优先级的确定也可以分为静态优先级（事先根据进程类型，进程对资源的需求，用户要求等方面确定一个固定值）；动态优先级（随进程的推进或者等待时间而增加或者减少）
4. 高相应比算法HRN：响应比=(等待时间+要求服务时间)/要求服务时间；
5. 时间片轮转调度RR：按到达的先后对进程放入队列中，然后给队首进程分配CPU时间片，时间片用完之后计时器发出中断，暂停当前进程并将其放到队列尾部，循环
6. 多级反馈队列调度算法：目前公认较好的调度算法；设置多个就绪队列并为每个队列设置不同的优先级，第一个队列优先级最高，其余依次递减。优先级越高的队列分配的时间片越短，进程到达之后按FCFS放入第一个队列，如果调度执行后没有完成，那么放到第二个队列尾部等待调度，如果第二次调度仍然没有完成，放入第三队列尾部…。只有当前一个队列为空的时候才会去调度下一个队列的进程。

实时调度算法：
1. 最早截止时间优先调度算法EDF：算法根据任务的开始截止时间确定优先级，截止时间越早，优先级越高。算法维护一个实时就绪队列，最早截止时间的任务排在最前面；可以用于抢占式调度也可以用于非抢占式调度；
2. 最低松弛度优先调度算法LLF：松弛度=(必须完成时间-本身运行时间-当前时间);算法根据任务的松弛度确定任务的优先级，松弛度代表了任务的紧急程度，任务的紧急程度越高，被赋予的优先级越高
  死锁的必要条件以及处理方式

死锁是指多个进程在运行过程中，因为争夺资源而造成的一种僵局，如果没有外力推进，处于僵局中的进程就无法继续执行。

死锁原因：
1. 竞争资源：请求同一有限资源的进程数多于可用资源数
2. 进程推进顺序非法：进程执行中，请求和释放资源顺序不合理，如资源等待链

死锁产生的必要条件：
1. 互斥条件:进程对所分配的资源进行排他性的使用
2. 请求和保持条件：进程被阻塞的时候并不释放锁申请到的资源
3. 不可剥夺条件：进程对于已经申请到的资源在使用完成之前不可以被剥夺
4. 环路等待条件：发生死锁的时候存在的一个 进程-资源 环形等待链

死锁处理：
1. 预防死锁：破坏产生死锁的4个必要条件中的一个或者多个；实现起来比较简单，但是如果限制过于严格会降低系统资源利用率以及吞吐量
2. 避免死锁：在资源的动态分配中，防止系统进入不安全状态(可能产生死锁的状态)-如银行家算法
3. 检测死锁：允许系统运行过程中产生死锁，在死锁发生之后，采用一定的算法进行检测，并确定与死锁相关的资源和进程，采取相关方法清除检测到的死锁。实现难度大
4. 解除死锁：与死锁检测配合，将系统从死锁中解脱出来（撤销进程或者剥夺资源）。对检测到的和死锁相关的进程以及资源，通过撤销或者挂起的方式，释放一些资源并将其分配给处于阻塞状态的进程，使其转变为就绪态。实现难度大

死锁定理：S为死锁状态的充分条件是，当且仅当S的资源分配图是不能完全简化的
内存管理方式-段式页式和段页式

由于连续内存分配方式(单一连续分配，固定分区分配，动态分区分配，动态重定位分区分配)导致的内存利用率偏低以及内存碎片的问题，进而引出离散的内存分配方式。离散内存分配可以从OS的内存管理角度引出页式(离散分配的基本单位是页)管理，也可以从程序编制角度引出段式(离散分配的基本单位是段)管理。
基本分页存储管理

基本分页存储管理中不具备页面置换功能(即没有实现虚拟内存的功能)，因此需要整个程序的所有页面都装入内存之后才可以运行。因为程序数据存储在不同的页面中，而页面又离散的分布在内存中，因此需要一个页表来记录逻辑地址和实际存储地址之间的映射关系，以实现从页号到物理块号的映射。由于页表也是存储在内存中的，因此和不适用分页管理的存储方式相比，访问分页系统中内存数据需要两次的内存访问(一次是从内存中访问页表，从中找到指定的物理块号，加上页内偏移得到实际物理地址；第二次就是根据第一次得到的物理地址访问内存取出数据)。
为了减少两次访问内存导致的效率影响，分页管理中引入了快表(或者联想寄存器)机制，包含快表机制的内存管理中，当要访问内存数据的时候，首先将页号在快表中查询，如果查找到说明要访问的页表项在快表中，那么直接从快表中读取相应的物理块号；如果没有找到，那么访问内存中的页表，从页表中得到物理地址，同时将页表中的该映射表项添加到快表中(可能存在快表换出算法)。
在某些计算机中如果内存的逻辑地址很大，将会导致程序的页表项会很多，而页表在内存中是连续存放的，所以相应的就需要较大的连续内存空间。为了解决这个问题，可以采用两级页表或者多级页表的方法，其中外层页表一次性调入内存且连续存放，内层页表离散存放。相应的访问内存页表的时候需要一次地址变换，访问逻辑地址对应的物理地址的时候也需要一次地址变换，而且一共需要访问内存3次才可以读取一次数据。
基本分段存储管理方式

分页是为了提高内存利用率，而分段是为了满足程序员在编写代码的时候的一些逻辑需求(比如数据共享，数据保护，动态链接等)。
分段内存管理当中，地址是二维的，一维是段号，一维是段内地址；其中每个段的长度是不一样的，而且每个段内部都是从0开始编址的。由于分段管理中，每个段内部是连续内存分配，但是段和段之间是离散分配的，因此也存在一个逻辑地址到物理地址的映射关系，相应的就是段表机制。段表中的每一个表项记录了该段在内存中的起始地址和该段的长度。段表可以放在内存中也可以放在寄存器中。
访问内存的时候根据段号和段表项的长度计算当前访问段在段表中的位置，然后访问段表，得到该段的物理地址，根据该物理地址以及段内偏移量就可以得到需要访问的内存。由于也是两次内存访问，所以分段管理中同样引入了联想寄存器。

分段和分页的对比：
1. 页是信息的物理单位，是出于系统内存利用率的角度提出的离散分配机制；段是信息的逻辑单位，每个段含有一组意义完整的信息，是出于用户角度提出的内存管理机制
2. 页的大小是固定的，由系统决定；段的大小是不确定的，由用户决定
3. 页地址空间是一维的，段地址空间是二维的
  段页式存储管理

先将用户程序分为若干个段，然后再把每个段分成若干个页，并且为每一个段赋予一个段名称。这样在段页式管理中，一个内存地址就由段号，段内页号以及页内地址三个部分组成。
段页式内存访问：系统中设置了一个段表寄存器，存放段表的起始地址和段表的长度。地址变换时，根据给定的段号（还需要将段号和寄存器中的段表长度进行比较防止越界）以及寄存器中的段表起始地址，就可以得到该段对应的段表项，从段表项中得到该段对应的页表的起始地址，然后利用逻辑地址中的段内页号从页表中找到页表项，从该页表项中的物理块地址以及逻辑地址中的页内地址拼接出物理地址，最后用这个物理地址访问得到所需数据。由于访问一个数据需要三次内存访问，所以段页式管理中也引入了高速缓冲寄存器。
虚拟内存及页面置换算法

如果存在一个程序，所需内存空间超过了计算机可以提供的实际内存，那么由于该程序无法装入内存所以也就无法运行。单纯的增加物理内存只能解决一部分问题，但是仍然会出现无法装入单个或者无法同时装入多个程序的问题。但是可以从逻辑的角度扩充内存容量，即可解决上述两种问题。

虚拟存储器就是具有请求调入功能和置换功能，可以从逻辑上对内存容量加以扩充的一种存储器系统。虚拟存储器都是建立在离散内存管理的基础上

虚拟存储器的特征：
1. 多次性：一个作业可以分多次被调入内存。多次性是虚拟存储特有的属性
2. 对换性：作业运行过程中存在换进换出的过程(换出暂时不用的数据换入需要的数据)
3. 虚拟性：虚拟性体现在其从逻辑上扩充了内存的容量(可以运行实际内存需求比物理内存大的应用程序)。虚拟性是虚拟存储器的最重要特征也是其最终目标。虚拟性建立在多次性和对换性的基础上行，多次性和对换性又建立在离散分配的基础上
  页面置换算法

4.   最佳置换算法：只具有理论意义的算法，用来评价其他页面置换算法。置换策略是将当前页面中在未来最长时间内不会被访问的页置换出去。
     先进先出置换算法：简单粗暴的一种置换算法，没有考虑页面访问频率信息。每次淘汰最早调入的页面
     最近最久未使用算法LRU：算法赋予每个页面一个访问字段，用来记录上次页面被访问到现在所经历的时间t，每次置换的时候把t值最大的页面置换出去(实现方面可以采用寄存器或者栈的方式实现)
     时钟算法clock(也被称为是最近未使用算法NRU)：页面设置一个访问为，并将页面链接为一个环形队列，页面被访问的时候访问位设置为1。页面置换的时候，如果当前指针所指页面访问为为0，那么置换，否则将其置为0，循环直到遇到一个访问为位0的页面
     改进型Clock算法：在Clock算法的基础上添加一个修改位，替换时根究访问位和修改位综合判断。优先替换访问为何修改位都是0的页面，其次是访问位为0修改位为1的页面。
     最少使用算法LFU：设置寄存器记录页面被访问次数，每次置换的时候置换当前访问次数最少的。存在问题是该访问寄存器并不能真正反映当前页面访问次数，因为访问速度比较快，所以在更新寄存器的时间间隔内访问1次和访问100次都是一样的。另外，LFU和LRU是很类似的，支持硬件也是一样的，但是区分两者的关键在于一个以时间为标准，一个以次数为标准(例如对于寄存器 pa 001111 和pb 111000，两个页面，如果采用LRU，那么被淘汰的是pa，如果采用LFU那么被淘汰的是pb)。
     页面缓冲算法PBA：置换的时候，页面无论是否被修改过，都不被置换到磁盘，而是先暂留在内存中的页面链表(已修改页面链表和未修改页面链表，也可以不区分)里面，当其再次被访问的时候可以直接从这些链表中取出而不必进行磁盘IO，当链表中已修改也难数目达到一定数量之后，进行依次写磁盘操作(相当于将多次IO合并为一次)
   ————————————————



https://www.cnblogs.com/dear_diary/p/10339926.html

**进程：**

目的：更好地描述和控制程序并发执行；

定义：进程是进程实体的一次运行，是系统进行资源分配和调度的一个独立单位；

组成：

- PCB：保存进程运行期间相关的数据，是进程存在的唯一标志
- 程序段：能被进程调度程序调度到CPU运行的程序代码段
- 数据段：存储程序运行期间的相关数据，可以是原始数据也可以是相关结果

进程状态：

- 状态种类：
  - 运行状态：进程正在处理机上运行
  - 就绪状态：进程已获得除处理机之外的一切所需资源
  - 阻塞状态：进程正在等待某一事件而暂停运行
  - 创建状态：进程正在被创建，尚未转到就绪状态
    - 创建完成后转到就绪状态
  - 结束状态：进程正从系统中消失，分为正常结束和异常退出
- 状态变化：
  - 就绪->运行：经过处理机调度，就绪进程得到处理机资源
  - 运行->就绪：时间片用完或在可剥夺系统中有更高优先级进程进入
  - 运行->阻塞：进行需要的某一资源还没准备好
  - 阻塞->就绪：进程需要的资源已准备好

进程控制：

- 创建：终端用户登录系统、作业调度、系统提供服务、用户程序的应用请求等；
- 终止：正常结束、发生异常、外界干预
- 阻塞：等待资源
- 唤醒：资源到达
- 切换：时间片用完、主动放弃处理机、被更高优先级的进程剥夺处理机





https://blog.csdn.net/FanceFu/article/details/79357048?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase

## 操作系统基本特征

### 1. 并发

并发性是指宏观上在一段时间内能同时运行多个程序，而并行性则指同一时刻能运行多个指令。

并行需要硬件支持，如多流水线或者多处理器。

操作系统通过引入进程和线程，使得程序能够并发运行。

### 2. 共享

共享是指系统中的资源可以供多个并发的进程共同使用。

有两种共享方式：互斥共享和同时共享。

互斥共享的资源称为临界资源，例如打印机等，在同一时间只允许一个进程访问，否则会出现错误，需要用同步机制来实现对临界资源的访问。

### 3. 虚拟

虚拟技术把一个物理实体转换为多个逻辑实体。主要有两种虚拟技术：时分复用技术和空分复用技术，例如多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占有处理器，每次只执行一小个时间片并快速切换，这样就好像有多个处理器进行处理。

### 4. 异步

异步是指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。

## 系统调用

如果一个进程在用户态需要用到操作系统的一些功能，就需要使用系统调用从而陷入内核，由操作系统代为完成。

可以由系统调用请求的功能有设备管理、文件管理、进程管理、进程通信、存储器管理等。

## 中断分类

### 1. 外中断

由 CPU 执行指令以外的事件引起，如 I/O 结束中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。

### 2. 异常

由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。

### 3. 陷入

在用户程序中使用系统调用。

## 大内核和微内核

### 1. 大内核

大内核是将操作系统功能作为一个紧密结合的整体放到内核，由于各模块共享信息，因此有很高的性能。

### 2. 微内核

由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。移出的部分根据分层的原则划分成若干服务，相互独立。但是需要频繁地在用户态和核心态之间进行切换，会有一定的性能损失。

# 第二章 进程管理

## 进程与线程

### 1. 进程

进程是操作系统进行资源分配的基本单位。

进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。

### 2. 线程

一个线程中可以有多个线程，是独立调度的基本单位。同一个进程中的多个线程之间可以并发执行，它们共享进程资源。

### 3. 区别

① 拥有资源：进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问率属进程的资源。

② 调度：线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程内的线程切换到另一个进程中的线程时，会引起进程切换。

③ 系统开销：由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，因此操作系统所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置。而线程切换时只需保存和设置少量寄存器内容，开销很小。此外，由于同一进程内的多个线程共享进程的地址空间，因此，这些线程之间的同步与通信非常容易实现，甚至无需操作系统的干预。

④ 通信方面：进程间通信 (IPC) 需要进程同步和互斥手段的辅助，以保证数据的一致性，而线程间可以通过直接读/写进程数据段（如全局变量）来进行通信。

举例：QQ 和 浏览器是两个进程，浏览器进程里面有很多线程，例如 http 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 http 请求时，浏览器还可以响应用户的其它事件。

## 进程状态的切换

[![img](https://github.com/CyC2018/InterviewNotes/raw/master/pics/1706ce58-a081-4fed-9b36-c3c0d7e22b3a.jpg)](https://github.com/CyC2018/InterviewNotes/blob/master/pics/1706ce58-a081-4fed-9b36-c3c0d7e22b3a.jpg)

阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU，缺少 CPU 会让进程从运行态转换为就绪态。

只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。

## 调度算法

需要针对不同环境来讨论调度算法。

### 1. 批处理系统中的调度

#### 1.1 先来先服务（FCFS）

first-come first-serverd。

调度最先进入就绪队列的作业。

有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

#### 1.2 短作业优先（SJF）

shortest job first。

调度估计运行时间最短的作业。

长作业有可能会饿死，处于一直等待短作业执行完毕的状态。如果一直有短作业到来，那么长作业永远得不到调度。

#### 1.3 最短剩余时间优先（SRTN）

shortest remaining time next。

### 2. 交互式系统中的调度

#### 2.1 优先权优先

除了可以手动赋予优先权之外，还可以把响应比作为优先权，这种调度方式叫做高响应比优先调度算法。

响应比 = (等待时间 + 要求服务时间) / 要求服务时间 = 响应时间 / 要求服务时间

这种调度算法主要是为了解决 SJF 中长作业可能会饿死的问题，因为随着等待时间的增长，响应比也会越来越高。

#### 2.2 时间片轮转

将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 分配给队首的进程。

时间片轮转算法的效率和时间片有很大关系。因为每次进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太短，进程切换太频繁，在进程切换上就会花过多时间。

#### 2.3 多级反馈队列

[![img](https://github.com/CyC2018/InterviewNotes/raw/master/pics/042cf928-3c8e-4815-ae9c-f2780202c68f.png)](https://github.com/CyC2018/InterviewNotes/blob/master/pics/042cf928-3c8e-4815-ae9c-f2780202c68f.png)

① 设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片的大小也各不相同，在优先权越高的队列中，为每个进程所规定的执行时间片就越小。

② 当一个新进程进入内存后，首先将它放入第一队列的末尾，按 FCFS 原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时尚未完成，调度程序便将该进程转入下一个队列的队尾。

③ 仅当前 i -1 个队列均空时，才会调度第 i 队列中的进程运行。

优点：实时性好，也适合运行短作业和长作业。

#### 2.4 短进程优先

### 3. 实时系统中的调度

实时系统要一个服务请求在一个确定时间内得到响应。

分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

## 进程同步

### 1. 临界区

对临界资源进行访问的那段代码称为临界区。

为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

```
// entry section
// critical section;
// exit section
```

### 2. 同步与互斥

同步指多个进程按一定顺序执行；互斥指多个进程在同一时刻只有一个进程能进入临界区。

同步是在对临界区互斥访问的基础上，通过其它机制来实现有序访问的。

### 3. 信号量

**信号量（Samaphore）**是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

- **down** : 如果信号量大于 0 ，执行 - 1 操作；如果信号量等于 0，将进程睡眠，等待信号量大于 0；
- **up**：对信号量执行 + 1 操作，并且唤醒睡眠的进程，让进程完成 down 操作。

down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。

如果信号量的取值只能为 0 或者 1，那么就成为了**互斥量（Mutex）**，0 表示临界区已经加锁，1 表示临界区解锁。

```
typedef int samaphore;
samaphore mutex = 1;
void P1() {
    down(mutex);
    // 临界区
    up(mutex);
}

void P2() {
    down(mutex);
    // 临界区
    up(mutex);
}
```

**使用信号量实现生产者-消费者问题**

使用一个互斥量 mutex 来对临界资源进行访问；empty 记录空缓冲区的数量，full 记录满缓冲区的数量。

注意，必须先执行 down 操作再用互斥量对临界区加锁，否则会出现死锁。如果都先对临界区加锁，然后再执行 down 操作，考虑这种情况：生产者对临界区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生成者睡眠。消费者此时不能进入临界区，因为生产者对临界区加锁了，也就无法对执行 up(empty) 操作，那么生产者和消费者就会一直等待下去。

```
#define N 100
typedef int samaphore;
samaphore mutex = 1;
samaphore empty = N;
samaphore full = 0;

void producer() {
    while(TRUE){
        int item = produce_item;
        down(empty);
        down(mutex);
        insert_item(item);
        up(mutex);
        up(full);
    }
}

void consumer() {
    while(TRUE){
        down(full);
        down(mutex);
        int item = remove_item(item);
        up(mutex);
        up(empty);
        consume_item(item);
    }
}
```

### 4. 管程

使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。

c 语言不支持管程，下面的示例代码使用了类 Pascal 语言来描述管程。示例代码中的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。

```
monitor ProducerConsumer
    integer i;
    condition c;
    
    procedure insert();
    begin
    
    end;
    
    procedure remove();
    begin
    
    end;
end monitor;
```

管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，必须将进程阻塞，否者其它进程永远不能使用管程。

管程引入了 **条件变量** 以及相关的操作：**wait()** 和 **signal()** 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来让另一个进程持有。signal() 操作用于唤醒被阻塞的进程。

**使用管程实现生成者-消费者问题**

```
monitor ProducerConsumer
    condition full, empty;
    integer count := 0;
    condition c;

    procedure insert(item: integer);
    begin
        if count = N then wait(full);
        insert_item(item);
        count := count + 1;
        if count = 1 ten signal(empty);
    end;

    function remove: integer;
    begin
        if count = 0 then wait(empty);
        remove = remove_item;
        count := count - 1;
        if count = N -1 then signal(full);
    end;
end monitor;

procedure producer
begin
    while true do
    begin
        item = produce_item;
        ProducerConsumer.insert(item);
    end
end;

procedure consumer
begin
    while true do
    begin
        item = ProducerConsumer.remove;
        consume_item(item);
    end
end;
```

## 进程通信

进程通信可以看成是不同进程间的线程通信，对于同一个进程内线程的通信方式，主要使用信号量、条件变量等同步机制。

### 1. 管道

管道是单向的、先进先出的、无结构的、固定大小的字节流，它把一个进程的标准输出和另一个进程的标准输入连接在一起。写进程在管道的尾端写入数据，读进程在管道的首端读出数据。数据读出后将从管道中移走，其它读进程都不能再读到这些数据。

管道提供了简单的流控制机制，进程试图读空管道时，在有数据写入管道前，进程将一直阻塞。同样地，管道已经满时，进程再试图写管道，在其它进程从管道中移走数据之前，写进程将一直阻塞。

Linux 中管道是通过空文件来实现。

管道有三种：

① 普通管道：有两个限制：一是只支持半双工通信方式，即只能单向传输；二是只能在父子进程之间使用；

② 流管道：去除第一个限制，支持双向传输；

③ 命名管道：去除第二个限制，可以在不相关进程之间进行通信。

### 2. 信号量

信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其它进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

### 3. 消息队列

消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

### 4. 信号

信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

### 5. 共享内存

共享内存就是映射一段能被其它进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其它进程间通信方式运行效率低而专门设计的。它往往与其它通信机制（如信号量）配合使用，来实现进程间的同步和通信。

### 6. 套接字

套接字也是一种进程间通信机制，与其它通信机制不同的是，它可用于不同机器间的进程通信。

## 经典同步问题

生产者和消费者问题前面已经讨论过。

### 1. 读者-写者问题

允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。

一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。

```
typedef int semaphore;
semaphore count_mutex = 1;
semaphore data_mutex = 1;
int count = 0;

void reader() {
    while(TRUE) {
        down(count_mutex);
        count++;
        if(count == 1) down(data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问
        up(count_mutex);
        read();
        down(count_mutex);
        count--;
        if(count == 0) up(data_mutex);
        up(count_mutex);
    }
}

void writer() {
    while(TRUE) {
        down(data_mutex);
        write();
        up(data_mutex);
    }
}
```

### 2. 哲学家进餐问题

[![img](https://github.com/CyC2018/InterviewNotes/raw/master/pics/a9077f06-7584-4f2b-8c20-3a8e46928820.jpg)](https://github.com/CyC2018/InterviewNotes/blob/master/pics/a9077f06-7584-4f2b-8c20-3a8e46928820.jpg)

五个哲学家围着一张圆周，每个哲学家面前放着饭。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先一根一根拿起左右两边的筷子。

下面是一种错误的解法，考虑到如果每个哲学家同时拿起左手边的筷子，那么就无法拿起右手边的筷子，造成死锁。

```
#define N 5
#define LEFT (i + N - 1) % N
#define RIGHT (i + N) % N
typedef int semaphore;
semaphore chopstick[N];

void philosopher(int i) {
    while(TURE){
        think();
        down(chopstick[LEFT[i]]);
        down(chopstick[RIGHT[i]]);
        eat();
        up(chopstick[RIGHT[i]]);
        up(chopstick[LEFT[i]]);
    }
}
```

为了防止死锁的发生，可以加一点限制，只允许同时拿起左右两边的筷子，方法是引入一个互斥量，对拿起两个筷子的那段代码加锁。

```
semaphore mutex = 1;

void philosopher(int i) {
    while(TURE){
        think();
        down(mutex);
        down(chopstick[LEFT[i]]);
        down(chopstick[RIGHT[i]]);
        up(mutex);
        eat();
        down(mutex);
        up(chopstick[RIGHT[i]]);
        up(chopstick[LEFT[i]]);
        up(mutex);
    }
}
```

# 第三章 死锁

## 死锁的条件

[![img](https://github.com/CyC2018/InterviewNotes/raw/master/pics/c037c901-7eae-4e31-a1e4-9d41329e5c3e.png)](https://github.com/CyC2018/InterviewNotes/blob/master/pics/c037c901-7eae-4e31-a1e4-9d41329e5c3e.png)

1. 互斥
2. 请求与保持：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
3. 不可抢占
4. 环路等待

## 死锁的处理方法

### 1. 鸵鸟策略

把头埋在沙子里，假装根本没发生问题。

这种策略不可取。

### 2. 死锁预防

在程序运行之前预防发生死锁。

#### 2.1 破坏互斥条件

例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。

#### 2.2 破坏请求与保持条件

一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。

#### 2.3 破坏不可抢占条件

#### 2.4 破坏环路等待

给资源统一编号，进程只能按编号顺序来请求资源。

### 3. 死锁避免

在程序运行时避免发生死锁。

#### 3.1 安全状态

[![img](https://github.com/CyC2018/InterviewNotes/raw/master/pics/ed523051-608f-4c3f-b343-383e2d194470.png)](https://github.com/CyC2018/InterviewNotes/blob/master/pics/ed523051-608f-4c3f-b343-383e2d194470.png)

图 a 的第二列 has 表示已拥有的资源数，第三列 max 表示总共需要的资源数，free 表示还有可以使用的资源数。从图 a 开始出发，先让 B 拥有所需的所有资源，运行结束后释放 B，此时 free 变为 4；接着以同样的方式运行 C 和 A，使得所有进程都能成功运行，因此可以称图 a 所示的状态时安全的。

定义：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。

#### 3.2 单个资源的银行家算法

一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。

[![img](https://github.com/CyC2018/InterviewNotes/raw/master/pics/d160ec2e-cfe2-4640-bda7-62f53e58b8c0.png)](https://github.com/CyC2018/InterviewNotes/blob/master/pics/d160ec2e-cfe2-4640-bda7-62f53e58b8c0.png)

上图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态。

#### 3.3 多个资源的银行家算法

[![img](https://github.com/CyC2018/InterviewNotes/raw/master/pics/62e0dd4f-44c3-43ee-bb6e-fedb9e068519.png)](https://github.com/CyC2018/InterviewNotes/blob/master/pics/62e0dd4f-44c3-43ee-bb6e-fedb9e068519.png)

上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。

检查一个状态是否安全的算法如下：

① 查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。

② 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。

③ 重复以上两步，直到所有进程都标记为终止，则状态时安全的。

### 4. 死锁检测与死锁恢复

不试图组织死锁，而是当检测到死锁发生时，采取措施进行恢复。

#### 4.1 死锁检测算法

死锁检测的基本思想是，如果一个进程所请求的资源能够被满足，那么就让它执行，释放它拥有的所有资源，然后让其它能满足条件的进程执行。

[![img](https://github.com/CyC2018/InterviewNotes/raw/master/pics/e1eda3d5-5ec8-4708-8e25-1a04c5e11f48.png)](https://github.com/CyC2018/InterviewNotes/blob/master/pics/e1eda3d5-5ec8-4708-8e25-1a04c5e11f48.png)

上图中，有三个进程四个资源，每个数据代表的含义如下：

E 向量：资源总量A 向量：资源剩余量C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量R 矩阵：每个进程请求的资源数量

进程 P1 和 P2 所请求的资源都得不到满足，只有进程 P3 可以，让 P3 执行，之后释放 P3 拥有的资源，此时 A = (2 2 2 0)。P1 可以执行，执行后释放 P1 拥有的资源， A = (4 2 2 2) ，P2 也可以执行。所有进程都可以顺利执行，没有死锁。

算法总结如下：

每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。

① 寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。② 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 ①。③ 如果有没有这样一个进程，算法终止。

#### 4.2 死锁恢复

① 利用抢占恢复② 杀死进程

# 第四章 存储器管理

## 虚拟内存

每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一 页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。

当程序引用到一部分在物理内存中的地址空间时，由硬件立即执行必要的映射。当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的指令。

## 分页与分段

### 1. 分页

用户程序的地址空间被划分为若干固定大小的区域，称为“页”。相应地，内存空间分成若干个物理块，页和块的大小相等。可将用户程序的任一页放在内存的任一块中，实现了离散分配，由一个页表来维护它们之间的映射关系。

### 2. 分段

[![img](https://github.com/CyC2018/InterviewNotes/raw/master/pics/22de0538-7c6e-4365-bd3b-8ce3c5900216.png)](https://github.com/CyC2018/InterviewNotes/blob/master/pics/22de0538-7c6e-4365-bd3b-8ce3c5900216.png)

上图为一个编译器在编译过程中建立的多个表，有 4 个表是动态增长的，如果使用分页系统的一维地址空间，动态递增的特点会导致覆盖问题的出现。

[![img](https://github.com/CyC2018/InterviewNotes/raw/master/pics/e0900bb2-220a-43b7-9aa9-1d5cd55ff56e.png)](https://github.com/CyC2018/InterviewNotes/blob/master/pics/e0900bb2-220a-43b7-9aa9-1d5cd55ff56e.png)

分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，可以动态改变。

每个段都需要程序员来划分。

### 3. 段页式

用分段方法来分配和管理虚拟存储器。程序的地址空间按逻辑单位分成基本独立的段，而每一段有自己的段名，再把每段分成固定大小的若干页。

用分页方法来分配和管理实存。即把整个主存分成与上述页大小相等的存储块，可装入作业的任何一页。程序对内存的调入或调出是按页进行的。但它又可按段实现共享和保护。

### 4. 分页与分段区别

① 对程序员的透明性：分页透明，但是分段需要程序员显示划分每个段。

② 地址空间的维度：分页是一维地址空间，分段是二维的。

③ 大小是否可以改变：页的大小不可变，段的大小可以动态改变。

④ 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。

## 页面置换算法

在程序运行过程中，若其所要访问的页面不在内存而需要把它们调入内存，但是内存已无空闲空间时，系统必须从内存中调出一个页面到磁盘对换区中，并且将程序所需要的页面调入内存中。页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

### 1. 最佳（Optimal）

所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。

是一种理论上的算法，因为无法知道一个页面多长时间会被再访问到。

举例：一个系统为某进程分配了三个物理块，并有如下页面引用序列：

7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1

进程运行时，先将 7,0,1 三个页面装入内存。当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。

### 2. 先进先出（FIFO）

所选择换出的页面是最先进入的页面。

该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。

### 3. 最近最久未使用（LRU, Least Recently Used）

虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。

可以用栈来实现该算法，栈中存储页面的页面号。当进程访问一个页面时，将该页面的页面号从栈移除，并将它压入栈顶，这样，最近被访问的页面的页面号总是在栈顶，而最近最久未使用的页面的页面号总是在栈底。

4，7，0，7，1，0，1，2，1，2，6

[![img](https://github.com/CyC2018/InterviewNotes/raw/master/pics/eb859228-c0f2-4bce-910d-d9f76929352b.png)](https://github.com/CyC2018/InterviewNotes/blob/master/pics/eb859228-c0f2-4bce-910d-d9f76929352b.png)

### 4. 时钟（Clock）

Clock 页面置换算法需要用到一个访问位，当一个页面被访问时，将访问为置为 1。

首先，将内存中的所有页面链接成一个循环队列，当缺页中断发生时，检查当前指针所指向页面的访问位，如果访问位为 0，就将该页面换出；否则将该页的访问位设置为 0，给该页面第二次的机会，移动指针继续检查。

# 第五章 设备管理

## 磁盘调度算法

当多个进程同时请求访问磁盘时，需要进行磁盘调度来控制对磁盘的访问。磁盘调度的主要目标是使磁盘的平均寻道时间最少。

### 1. 先来先服务（FCFS, First Come First Serverd）

根据进程请求访问磁盘的先后次序来进行调度。优点是公平和简单，缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。

### 2. 最短寻道时间优先（SSTF, Shortest Seek Time First）

要求访问的磁道与当前磁头所在磁道距离最近的优先进行调度。这种算法并不能保证平均寻道时间最短，但是比 FCFS 好很多。

### 3. 扫描算法（SCAN）

SSTF 会出现进行饥饿现象。考虑以下情况，新进程请求访问的磁道与磁头所在磁道的距离总是比一个在等待的进程来的近，那么等待的进程会一直等待下去。

SCAN 算法在 SSTF 算法之上考虑了磁头的移动方向，要求所请求访问的磁道在磁头当前移动方向上才能够得到调度。因为考虑了移动方向，那么一个进程请求访问的磁道一定会得到调度。

当一个磁头自里向外移动时，移到最外侧会改变移动方向为自外向里，这种移动的规律类似于电梯的运行，因此又常称 SCAN 算法为电梯调度算法。

### 4. 循环扫描算法（CSCAN）

CSCAN 对 SCAN 进行了改动，要求磁头始终沿着一个方向移动。