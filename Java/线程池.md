CAS：compare and swap  -- compare and exchange -- 比较交换

具体：线程a读取数据为0，进行一系列操作后，要把该数据加1，再次读取，若该数据仍为0，直接改为1，若数据已被其他线程改为其他值，则重新读取操作，直到所读数据前后不变

在上面过程中可能会出现一种情况 -- ABA，

例：a线程读取共享数据为0，..., 其他线程也读取该数据并修改，经过多次修改，最后共享数据仍为0. 而a线程读取前后值一样。



原文链接：https://blog.csdn.net/weixin_40271838/article/details/79998327?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase

其他参考：https://www.cnblogs.com/xslbk/p/7266488.html



关于线程和线程池的学习，我们可以从以下几个方面入手：

第一，什么是线程，线程和进程的区别是什么

第二，线程中的基本概念，线程的生命周期

第三，单线程和多线程

第四，线程池的原理解析

第五，常见的几种线程池的特点以及各自的应用场景

## 一、线程与进程

线程，程序执行流的最小执行单位，是行程中的实际运作单位，经常容易和进程这个概念混淆。那么，线程和进程究竟有什么区别呢？首先，进程是一个动态的过程，是一个活动的实体。简单来说，一个应用程序的运行就可以被看做是一个进程，而线程，是运行中的实际的任务执行者。可以说，进程中包含了多个可以同时运行的线程。

## 二、线程的生命周期

线程的生命周期，线程的生命周期可以利用以下的图解来更好的理解：

![img](https://img-blog.csdn.net/20180418230837516?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDI3MTgzOA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)


第一步，是用new Thread()的方法新建一个线程，在线程创建完成之后，线程就进入了就绪（Runnable）状态，此时创建出来的线程进入抢占CPU资源的状态，当线程抢到了CPU的执行权之后，线程就进入了运行状态（Running），当该线程的任务执行完成之后或者是非常态的调用的stop（）方法之后，线程就进入了死亡状态。而我们在图解中可以看出，线程还具有一个则色的过程，这是怎么回事呢？当面对以下几种情况的时候，容易造成线程阻塞，第一种，当线程主动调用了sleep（）方法时，线程会进入则阻塞状态，除此之外，当线程中主动调用了阻塞时的IO方法时，这个方法有一个返回参数，当参数返回之前，线程也会进入阻塞状态，还有一种情况，当线程进入正在等待某个通知时，会进入阻塞状态。那么，为什么会有阻塞状态出现呢？我们都知道,CPU的资源是十分宝贵的，所以，当线程正在进行某种不确定时长的任务时，Java就会收回CPU的执行权，从而合理应用CPU的资源。我们根据图可以看出，线程在阻塞过程结束之后，会重新进入就绪状态，重新抢夺CPU资源。这时候，我们可能会产生一个疑问，如何跳出阻塞过程呢?又以上几种可能造成线程阻塞的情况来看，都是存在一个时间限制的，当sleep()方法的睡眠时长过去后，线程就自动跳出了阻塞状态，第二种则是在返回了一个参数之后，在获取到了等待的通知时，就自动跳出了线程的阻塞过程

## 三、单线程与多线程

什么是单线程和多线程？

单线程，顾名思义即是只有一条线程在执行任务，这种情况在我们日常的工作学习中很少遇到，所以我们只是简单做一下了解

多线程，创建多条线程同时执行任务，这种方式在我们的日常生活中比较常见。但是，在多线程的使用过程中，还有许多需要我们了解的概念。比如，在理解上并行和并发的区别，以及在实际应用的过程中多线程的安全问题，对此，我们需要进行详细的了解。

并行和并发：在我们看来，都是可以同时执行多种任务，那么，到底他们二者有什么区别呢？

并发，从宏观方面来说，并发就是同时进行多种时间，实际上，这几种时间，并不是同时进行的，而是交替进行的，而由于CPU的运算速度非常的快，会造成我们的一种错觉，就是在同一时间内进行了多种事情

而并发，则是真正意义上的同时进行多种事情。这种只可以在多核CPU的基础下完成。

还有就是多线程的安全问题？为什么会造成多线程的安全问题呢？我们可以想象一下，如果多个线程同时执行一个任务，name意味着他们共享同一种资源，由于线程CPU的资源不一定可以被谁抢占到，这是，第一条线程先抢占到CPU资源，他刚刚进行了第一次操作，而此时第二条线程抢占到了CPU的资源，name，共享资源还来不及发生变化，就同时有两条数据使用了同一条资源，具体请参考多线程买票问题。这个问题我们应该如何解决那？

  有造成问题的原因我们可以看出，这个问题主要的矛盾在于，CPU的使用权抢占和资源的共享发生了冲突，解决时，我们只需要让一条线程战歌了CPU的资源时，阻止第二条线程同时抢占CPU的执行权，在代码中，我们只需要在方法中使用同步代码块即可。在这里，同步代码块不多进行赘述，可以自行了解。



## 四，线程池

又以上介绍我们可以看出，在一个应用程序中，我们需要多次使用线程，也就意味着，我们需要多次创建并销毁线程。而创建并销毁线程的过程势必会消耗内存。而在Java中，内存资源是及其宝贵的，所以，我们就提出了线程池的概念。线程池是一种**生产者——消费者模式**

### 1 什么是线程池

线程池就是创建若干个可执行的线程放入一个池（容器）中，有任务需要处理时，会提交到线程池中的任务队列，处理完之后线程并不会被销毁，而是仍然在线程池中等待下一个任务。

### 2 使用线程池有什么好处

(1).降低资源消耗，通过重复利用已经创建的线程降低线程创建和销毁造成的消耗

(2).提高响应速度，当任务达到时，任务可以不需要的等到线程创建就能够立即执行

(3).提高线程的可管理性，性程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，故使用

​     线程池可以进行统一的分配，调用和监控，但是也要做到合理的利用线程池，所以要对线程池的原理了如指掌

### 3 线程池的生命周期

![img](https://img-blog.csdnimg.cn/20190518111829993.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbmZlbmdsb3ZlSVQ=,size_16,color_FFFFFF,t_70)

**RUNNING**：能接受新提交的任务，并且也能处理阻塞队列中的任务；

**SHUTDOWN**：关闭状态，不再接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务；（继续执行已添加线程）

**STOP**：（执行shutdownNow() ）不能接受新任务，也不处理队列中的任务，会中断正在处理任务的线程；（发出中断请求）

**TIDYING**：如果所有的任务都已终止了，workerCount（有效线程数）为0，线程池进入该状态后会调用 terminated() 方法进入 TERMINATED 状态；

**TERMINATED**：在terminated() 方法执行完后进入该状态，默认 terminated() 方法中什么也没有做。

### 4 创建线程池

#### 4.1 ThreadPoolExecutor --重点

那么，我们应该如何创建一个线程池那?Java中已经提供了创建线程池的一个类：Executor

而我们创建时，一般使用它的子类：**ThreadPoolExecutor**.

```
public ThreadPoolExecutor(int corePoolSize,  
                              int maximumPoolSize,  
                              long keepAliveTime,  
                              TimeUnit unit,  
                              BlockingQueue<Runnable> workQueue,  
                              ThreadFactory threadFactory,  
                              RejectedExecutionHandler handler)
```

四个构造方法 https://blog.csdn.net/u010723709/article/details/50377543

```
ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue<Runnable> workQueue)

ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue<Runnable> workQueue, RejectedExecutionHandler handler)

ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue<Runnable> workQueue, ThreadFactory threadFactory)

ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue<Runnable> workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler)
```



##### 4.1.1 参数解析

https://blog.csdn.net/fengye454545/article/details/79536986

这是其中最重要的一个构造方法，这个方法决定了创建出来的线程池的各种属性，下面依靠一张图来更好的理解线程池和这几个参数：

![img](https://img-blog.csdn.net/20180419002550514)

**corePoolSize**:  线程池中核心线程的数量

**maximumPoolSize**:  线程池中最大线程数量 (核心线程数 + 非核心线程数-- 临时线程)

**keepAliveTime**: 非核心线程的超时时长，当系统中非核心线程闲置时间超过keepAliveTime之后，则会被回收。如果ThreadPoolExecutor的allowCoreThreadTimeOut属性设置为true，则该参数也表示核心线程的超时时长

**unit**：TimeUnit，线程活动保持时间的单位，可选的单位有天（DAYS），小时（HOURS），分钟（MINUTES），毫秒(MILLISECONDS)，微秒(MICROSECONDS, 千分之一毫秒)和毫微秒(NANOSECONDS, 千分之一微秒)。

**workQueue**: 线程池中的任务队列，该队列主要用来存储已经被提交但是尚未执行的任务。存储在这里的任务是由ThreadPoolExecutor的execute方法提交来的。行的是FIFIO原则（先进先出）。

**threadFactory**:  为线程池提供创建新线程的功能，这个我们一般使用默认即可

**handler**：拒绝策略，当线程无法执行新任务时（一般是由于线程池中的线程数量已经达到最大数或者线程池关闭导致的），默认情况下，当线程池无法处理新线程时，会抛出一个RejectedExecutionException。

##### 4.1.2 线程池的执行流程又是怎样的呢？

![img](https://img-blog.csdn.net/2018041900353665)

有图我们可以看出，任务进来时，首先执行判断，判断核心线程是否处于空闲状态，如果不是，核心线程就先就执行任务，如果核心线程已满，则判断任务队列是否有地方存放该任务，若果有，就将任务保存在任务队列中，等待执行，如果满了，在判断最大可容纳的线程数，如果没有超出这个数量，就开创非核心线程执行任务，如果超出了，就调用handler实现拒绝策略。

解析：有新线程请求进来 --> 判断核心线程数是否已满（coreThreadSize）--> 有位置进入，已满则安排进入阻塞队列 --> 队列若满则判断临时线程是否已满（maximumPoolSize- coreThreadSize） -> 未满，进入；满了调用拒绝策略处理

##### 4.1.3 阻塞队列

https://www.cnblogs.com/xslbk/p/7266488.html

阻塞队可以选择如下几个

**ArrayBlockingQueue**: 是一个基于**数组**结构的有界阻塞队列，此队列按FIFO(先进先出)原则对元素进行排序。

**LinkedBlockingQueue**: 一个基于**链表**结构的阻塞队列，此队列按FIFO(先进先出)排序元素，吞吐量通常要高于ArrayBlockingQueue，静态工厂方法Executors.newFixedThreadPool()使用了这个队列。

**SynchronousQueue**: 一个不存储的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列。

**PriorityBlockingQueue**: 一个具有优先级得无限阻塞队列。

##### 4.1.4 RejectedExecutionHandler 拒绝策略：

有四种：这个策略默认情况下是AbortPolicy，表示无法处理新任务时抛出异常。

第一种**AbortPolicy**: 不执行新任务，直接抛出异常，提示线程池已满;

第二种**DisCardPolicy**: 不执行新任务，也不抛出异常;

第三种**DisCardOldSetPolicy**: 将消息队列中的第一个任务替换为当前新进来的任务执行;

第四种**CallerRunsPolicy**: 直接调用execute来执行当前任务

同时也可以根据应用场景需要来实现RejectedExecutionHandler接口自定义策略

##### 4.1.5 例子

```java
final ThreadPoolExecutor pool = new ThreadPoolExecutor(2,3,60,TimeUnit.SECONDS, new ArrayBlockingQueue<Runnable>(5),Executors.defaultThreadFactory());

for(int i = 0; i < 9; i++){
  pool.executor(new Task(i));
}

pool.shutdown();
```



#### 4.2 ExecutorService 

​	-- 阿里不使用，基于ThreadPoolExecutor 实现

![img](https://img-blog.csdn.net/20180823094933478?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NTgyNjA0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

##### 4.2.1 简单案例

```java
public class CacheThreadPoolDemo{
  
  public static void main(String[] args) {
    ExecutorService executorService = Executors.newCachedThreadPool();
    for(int i = 0; i<20; i++){
      executorService.executor(new Task());
    }
    
    executorSerice.shutdown();
  }
}
```

##### 4.2.2 Executors 工具类四种线程池的实现

```java
/**
     * Creates an Executor that uses a single worker thread operating
     * off an unbounded queue. (Note however that if this single
     * thread terminates due to a failure during execution prior to
     * shutdown, a new one will take its place if needed to execute
     * subsequent tasks.)  Tasks are guaranteed to execute
     * sequentially, and no more than one task will be active at any
     * given time. Unlike the otherwise equivalent
     * {@code newFixedThreadPool(1)} the returned executor is
     * guaranteed not to be reconfigurable to use additional threads.
     *
     * @return the newly created single-threaded Executor
     */
    public static ExecutorService newSingleThreadExecutor() {
        return new FinalizableDelegatedExecutorService
            (new ThreadPoolExecutor(1, 1,
                                    0L, TimeUnit.MILLISECONDS,
                                    new LinkedBlockingQueue<Runnable>()));
    }

public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) {
        return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue<Runnable>(),
                                      threadFactory);
    }

public static ExecutorService newCachedThreadPool() {
        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                      60L, TimeUnit.SECONDS,
                                      new SynchronousQueue<Runnable>());
    }
```

```java
public static ScheduledExecutorService newScheduledThreadPool(
            int corePoolSize, ThreadFactory threadFactory) {
        return new ScheduledThreadPoolExecutor(corePoolSize, threadFactory);
    }


public class ScheduledThreadPoolExecutor
        extends ThreadPoolExecutor
        implements ScheduledExecutorService {
        
        public ScheduledThreadPoolExecutor(int corePoolSize,
                                       ThreadFactory threadFactory) {
        super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
              new DelayedWorkQueue(), threadFactory);
    }
    
    public <V> ScheduledFuture<V> schedule(Callable<V> callable,
                                           long delay,
                                           TimeUnit unit) {
        if (callable == null || unit == null)
            throw new NullPointerException();
        RunnableScheduledFuture<V> t = decorateTask(callable,
            new ScheduledFutureTask<V>(callable,
                                       triggerTime(delay, unit)));
        delayedExecute(t);
        return t;
    }
 
 public ScheduledFuture<?> scheduleAtFixedRate(Runnable command,
                                                  long initialDelay,
                                                  long period,
                                                  TimeUnit unit) {
        if (command == null || unit == null)
            throw new NullPointerException();
        if (period <= 0)
            throw new IllegalArgumentException();
        ScheduledFutureTask<Void> sft =
            new ScheduledFutureTask<Void>(command,
                                          null,
                                          triggerTime(initialDelay, unit),
                                          unit.toNanos(period));
        RunnableScheduledFuture<Void> t = decorateTask(command, sft);
        sft.outerTask = t;
        delayedExecute(t);
        return t;
    }
 
 )

```

ScheduledThreadPoolDemo 

```java
//延迟n时间执行
public class ScheduledThreadPoolDemo {
  public static void main(String[] args){
    ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(3);//corPoolSize
    System.out.println(System.currentTimeMills());
    scheduledExecutorService.schedule(new Runnable(){
      @Override
      public void run(){
        System.out.println("延迟三秒执行");
        System.out.println(System.currentTimeMillis());
      }
    },3,TimeUnit.SECONDS);//delay 3s
    scheduledExecutorService.shutdown();
  }
}

//延迟n时间开始执行，每隔m时间执行一次
public class ScheduledThreadPoolDemo2 {
  public static void main(String[] args){
    ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(1);//corPoolSize
    System.out.println(System.currentTimeMills());
    scheduledExecutorService.schedule(new Runnable(){
      @Override
      public void run(){
        System.out.println("1 -------延迟一秒执行，每三秒执行一次");
        System.out.println(System.currentTimeMillis());
      }
    },1，3,TimeUnit.SECONDS);//initialDelay 1s, period 3s
    scheduledExecutorService.shutdown();
  }
}
```

### 4.3 ForkJoinPool

思想：分而治之

![在这里插入图片描述](https://img-blog.csdnimg.cn/20181111222715853.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA4NDEyOTY=,size_16,color_FFFFFF,t_70)

fork() 和 join() 的作用：

fork()：开启一个新线程（或是重用线程池内的空闲线程），将任务交给该线程处理。
join()：等待该任务的处理线程处理完毕，获得返回值。
疑问：当任务分解得越来越细时，所需要的线程数就会越来越多，而且大部分线程处于等待状态？

## 五，四种常见的线程池：

CachedThreadPool:可缓存的线程池，该线程池中没有核心线程，非核心线程的数量为Integer.max_value，就是无限大，当有需要时创建线程来执行任务，没有需要时回收线程，适用于耗时少，任务量大的情况。

SecudleThreadPool:周期性执行任务的线程池，按照某种特定的计划执行线程中的任务，有核心线程，但也有非核心线程，非核心线程的大小也为无限大。适用于执行周期性的任务。

SingleThreadPool:只有一条线程来执行任务，适用于有顺序的任务的应用场景。

FixedThreadPool:定长的线程池，有核心线程，核心线程的即为最大的线程数量，没有非核心线程
————————————————
版权声明：本文为CSDN博主「weixin_40271838」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/weixin_40271838/article/details/79998327